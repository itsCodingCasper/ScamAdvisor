{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d342d6",
   "metadata": {},
   "source": [
    "# SEBI Fraud Detection System with AI Multi-Agent Workflow\n",
    "\n",
    "## Investment Fraud Prevention & Detection Platform\n",
    "\n",
    "This system leverages **LlamaIndex** multi-agent workflows with **Gemini 2.5 Pro** to create a comprehensive fraud detection platform that:\n",
    "\n",
    "1. **Scans online platforms** for suspicious investment offers, deepfake content, and fraudulent advisors\n",
    "2. **Monitors social media** for misleading stock tips and pump-and-dump schemes  \n",
    "3. **Analyzes corporate announcements** for authenticity and credibility scoring\n",
    "4. **Verifies advisor credentials** against regulatory databases\n",
    "5. **Provides real-time alerts** and risk assessments for retail investors\n",
    "\n",
    "The system uses advanced AI agents to protect retail investors from securities market fraud, aligned with SEBI's Safe Space initiative.\n",
    "\n",
    "**Requirements**: You need a Gemini API key from Google AI Studio. The system uses LlamaIndex for multi-agent orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f90148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-index in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.13.3)\n",
      "Requirement already satisfied: llama-index-utils-workflow in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.4.0)\n",
      "Requirement already satisfied: llama-index-llms-google-genai in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-tools-google in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.6.0)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.5.0)\n",
      "Requirement already satisfied: llama-index-core<0.14,>=0.13.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.13.3)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.5.0)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.9.2)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.5.4)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.5.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (0.5.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (2025.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (11.2.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (4.3.7)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.3->llama-index) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (4.13.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.14,>=0.13.3->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.3->llama-index) (1.20.1)\n",
      "Requirement already satisfied: griffe in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.3->llama-index) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.3->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.101.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=5.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.0.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.3->llama-index) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from httpx->llama-index-core<0.14,>=0.13.3->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from httpx->llama-index-core<0.14,>=0.13.3->llama-index) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.3->llama-index) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.3->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.3->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.3->llama-index) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.14,>=0.13.3->llama-index) (0.4.6)\n",
      "Requirement already satisfied: pyvis<0.4,>=0.3.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-utils-workflow) (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (9.0.2)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (4.1.1)\n",
      "Requirement already satisfied: google-genai<2,>=1.24.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-llms-google-genai) (1.31.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (2.40.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-genai<2,>=1.24.0->llama-index-llms-google-genai) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.3->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.3->llama-index) (2.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai<2,>=1.24.0->llama-index-llms-google-genai) (0.6.1)\n",
      "Requirement already satisfied: google-api-python-client<3,>=2.115.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-tools-google) (2.179.0)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3,>=0.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-tools-google) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=1.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-tools-google) (1.2.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client<3,>=2.115.0->llama-index-tools-google) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client<3,>=2.115.0->llama-index-tools-google) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client<3,>=2.115.0->llama-index-tools-google) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google) (1.26.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from google-auth-oauthlib<2,>=1.2.0->llama-index-tools-google) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google) (3.2.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.3->llama-index) (3.0.2)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.1.8)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk>3.8.1->llama-index) (2025.7.34)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=1.2.0->llama-index-tools-google) (3.3.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.3->llama-index) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.3->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.3->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.3->llama-index) (24.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (4.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.19.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (4.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (0.19.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sayan\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for fraud detection system\n",
    "%pip install llama-index llama-index-utils-workflow llama-index-llms-google-genai llama-index-tools-google\n",
    "%pip install beautifulsoup4 requests pandas numpy scikit-learn nltk textblob\n",
    "%pip install streamlit plotly dash flask sqlalchemy\n",
    "%pip install opencv-python pillow librosa tensorflow\n",
    "%pip install youtube-dl tweepy selenium webdriver-manager\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baffd0",
   "metadata": {},
   "source": [
    "## Setup Gemini 2.5 Pro for Fraud Detection\n",
    "\n",
    "The fraud detection system uses **Gemini 2.5 Pro** as the core reasoning engine for all AI agents. Each agent specializes in different types of fraud detection:\n",
    "\n",
    "- **Content Analysis Agent**: Analyzes text, images, and videos for fraud indicators\n",
    "- **Advisor Verification Agent**: Cross-references advisor credentials with regulatory databases  \n",
    "- **Social Media Monitor Agent**: Scans platforms for suspicious investment schemes\n",
    "- **Corporate Announcement Agent**: Validates authenticity of company announcements\n",
    "- **Risk Assessment Agent**: Provides overall fraud risk scoring\n",
    "\n",
    "Make sure to set your Gemini API key as an environment variable (`GEMINI_API_KEY` or `GOOGLE_API_KEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5446091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fraud Detection System Initialized Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlparse\n",
    "import sqlite3\n",
    "\n",
    "# Web scraping and content analysis\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "# Machine learning for fraud detection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Optionally load .env if python-dotenv is installed\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    # load .env from the notebook directory (if present)\n",
    "    notebook_dir = Path().resolve()\n",
    "    load_dotenv(dotenv_path=notebook_dir / '.env')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "# Read API key from environment; support both GEMINI_API_KEY (user .env) and GOOGLE_API_KEY\n",
    "api_key = os.environ.get('GEMINI_API_KEY') or os.environ.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"Missing Gemini API key. Set the GEMINI_API_KEY or GOOGLE_API_KEY environment variable to your API key.\")\n",
    "\n",
    "# Initialize LLM for fraud detection system\n",
    "llm = GoogleGenAI(model=\"gemini-2.5-flash\", api_key=api_key)\n",
    "\n",
    "print(\"✅ Fraud Detection System Initialized Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adc7be",
   "metadata": {},
   "source": [
    "## Build Fraud Detection Tools & Database\n",
    "\n",
    "The fraud detection system uses multiple specialized tools and maintains databases for:\n",
    "\n",
    "1. **Regulatory Database**: SEBI registered advisors, brokers, and intermediaries\n",
    "2. **Fraud Patterns Database**: Known fraud indicators and suspicious content patterns  \n",
    "3. **Market Data Integration**: Real-time stock prices and trading volumes\n",
    "4. **Social Media Monitoring**: Scanning WhatsApp, Telegram, Twitter for suspicious activities\n",
    "5. **Content Analysis**: Deepfake detection, document verification, and authenticity checks\n",
    "\n",
    "We'll use Gemini's built-in Google Search capability along with custom tools for comprehensive fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f851e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fraud detection databases initialized!\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Create Google Search tool for fraud detection\n",
    "google_search_tool = types.Tool(\n",
    "    google_search=types.GoogleSearch()\n",
    ")\n",
    "\n",
    "# Enhanced LLM with search capabilities for fraud detection\n",
    "llm_with_search = GoogleGenAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=api_key,\n",
    "    generation_config=types.GenerateContentConfig(tools=[google_search_tool])\n",
    ")\n",
    "\n",
    "# Initialize fraud detection databases\n",
    "def init_fraud_databases():\n",
    "    \"\"\"Initialize SQLite databases for fraud detection system\"\"\"\n",
    "    \n",
    "    # Create regulatory database\n",
    "    conn = sqlite3.connect('../data/regulatory_db/sebi_advisors.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Table for registered advisors\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS registered_advisors (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT NOT NULL,\n",
    "            registration_number TEXT UNIQUE,\n",
    "            category TEXT,\n",
    "            validity_date TEXT,\n",
    "            status TEXT,\n",
    "            contact_info TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    # Table for fraud reports\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS fraud_reports (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            content_url TEXT,\n",
    "            fraud_type TEXT,\n",
    "            risk_score REAL,\n",
    "            detected_patterns TEXT,\n",
    "            verification_status TEXT,\n",
    "            reported_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    # Table for suspicious social media content\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS social_media_alerts (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            platform TEXT,\n",
    "            content TEXT,\n",
    "            user_handle TEXT,\n",
    "            fraud_indicators TEXT,\n",
    "            risk_level TEXT,\n",
    "            detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"✅ Fraud detection databases initialized!\")\n",
    "\n",
    "# Initialize the databases\n",
    "init_fraud_databases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0ec5d",
   "metadata": {},
   "source": [
    "## Test Fraud Detection Capabilities\n",
    "\n",
    "Let's test the system's ability to identify potential investment fraud by analyzing suspicious content and verifying information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a58d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 FRAUD DETECTION ANALYSIS:\n",
      "==================================================\n",
      "This investment offer contains multiple significant fraud indicators, and the provided advisor credentials appear to be illegitimate.\n",
      "\n",
      "**Fraud Indicators:**\n",
      "\n",
      "1.  **Unrealistic Returns:** The promise of \"500% returns in 30 days\" is an extreme and highly improbable claim for any legitimate investment. Such high, short-term returns are a classic characteristic of Ponzi schemes or other investment scams, as genuine investments always carry a degree of risk and rarely yield such rapid and substantial profits.\n",
      "2.  **Guaranteed Profits:** All legitimate investments carry inherent risks, and no financial advisor can truthfully \"guarantee profits.\" This assurance is a major red flag, as it misleads potential investors by eliminating the reality of market fluctuations and potential losses.\n",
      "3.  **\"Secret Trading Algorithm\":** The use of vague terms like a \"secret trading algorithm\" without providing any verifiable details or a track record is a common tactic employed by fraudsters. It creates an illusion of exclusive knowledge or advanced technology to entice investors without offering transparency or accountability.\n",
      "4.  **Exclusive WhatsApp Group for \"Insider Tips\":** This is a frequently used method in fraudulent schemes to foster a sense of exclusivity and urgency. Communication within closed groups makes it easier to control information, spread unverified claims, and pressure individuals into investing, while simultaneously making it harder for regulatory bodies to monitor the activities.\n",
      "\n",
      "**Verification of Advisor Credentials:**\n",
      "\n",
      "The provided license number, `SEBI/IA/2023/FAKE123`, is highly suspicious due to the inclusion of \"FAKE\" within the number itself.\n",
      "\n",
      "The Securities and Exchange Board of India (SEBI) is the regulatory authority for investment advisors in India, and legitimate advisors must be registered with SEBI. Investors can verify an advisor's registration on the official SEBI website by checking their RIA (Registered Investment Adviser) registration number.\n",
      "\n",
      "A direct search for the specific license number `SEBI/IA/2023/FAKE123` does not yield any valid registration. Furthermore, the format and the \"FAKE\" identifier strongly suggest that this is not a genuine SEBI registration number.\n",
      "\n",
      "While there are individuals named Raj Kumar who are associated with financial institutions or have faced SEBI actions, there is no indication that \"Raj Kumar\" with the license `SEBI/IA/2023/FAKE123` is a legitimate SEBI-registered investment advisor. In fact, SEBI has previously taken action against individuals with similar names, such as Rajiv Kumar Singh, for serious violations including promising assured returns and operating without proper certification.\n",
      "\n",
      "Given the combination of unrealistic promises, guarantees of profit, vague methodologies, the use of a closed communication channel, and a clearly fabricated license number, this investment offer exhibits all the hallmarks of a fraudulent scheme. Investors are strongly advised to avoid engaging with such offers and to only deal with SEBI-registered investment advisors whose credentials can be independently verified on the official SEBI website.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test fraud detection capabilities\n",
    "test_query = \"\"\"\n",
    "Analyze this suspicious investment offer: 'Get 500% returns in 30 days! \n",
    "Guaranteed profits with our secret trading algorithm. \n",
    "Contact advisor Raj Kumar (License: SEBI/IA/2023/FAKE123) \n",
    "Join our exclusive WhatsApp group for insider tips!'\n",
    "\n",
    "Please identify fraud indicators and verify the advisor credentials.\n",
    "\"\"\"\n",
    "\n",
    "response = llm_with_search.complete(test_query)\n",
    "print(\"🚨 FRAUD DETECTION ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "print(response)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af985f59",
   "metadata": {},
   "source": [
    "## Specialized Fraud Detection Agents\n",
    "\n",
    "The fraud detection system employs specialized AI agents that work together:\n",
    "\n",
    "### 🔍 **Content Scanner Agent**\n",
    "- Scans websites, social media, and documents for fraud indicators\n",
    "- Analyzes text patterns, promises of unrealistic returns, urgency tactics\n",
    "- Detects deepfake videos/audios and manipulated documents\n",
    "\n",
    "### ✅ **Advisor Verification Agent** \n",
    "- Cross-references advisor credentials with SEBI regulatory database\n",
    "- Validates registration numbers, licenses, and validity periods\n",
    "- Flags impersonators and unregistered entities\n",
    "\n",
    "### 📱 **Social Media Monitor Agent**\n",
    "- Monitors WhatsApp groups, Telegram channels, Twitter for suspicious tips\n",
    "- Detects pump-and-dump schemes and coordinated market manipulation\n",
    "- Tracks viral fraud content and fake trading apps\n",
    "\n",
    "### 📊 **Corporate Announcement Analyzer**\n",
    "- Verifies authenticity of company announcements\n",
    "- Cross-checks with historical filings and counterparty disclosures  \n",
    "- Provides credibility scoring based on company performance vs claims\n",
    "\n",
    "### ⚠️ **Risk Assessment Agent**\n",
    "- Aggregates findings from all agents\n",
    "- Generates comprehensive fraud risk scores\n",
    "- Creates actionable alerts for investors and regulators\n",
    "\n",
    "Each agent maintains state and can collaborate to provide comprehensive fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6459074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fraud Detection Tools Initialized Successfully!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Fraud Detection Tools\n",
    "async def scan_content_for_fraud(ctx: Context, content: str, content_type: str = \"text\") -> str:\n",
    "    \"\"\"Scans content (text/URL/document) for fraud indicators and suspicious patterns\"\"\"\n",
    "    \n",
    "    fraud_indicators = [\n",
    "        \"guaranteed returns\", \"secret algorithm\", \"insider tips\", \"risk-free\", \n",
    "        \"limited time offer\", \"exclusive opportunity\", \"500% returns\", \"get rich quick\",\n",
    "        \"investment guru\", \"proven strategy\", \"urgent action required\", \"act now\"\n",
    "    ]\n",
    "    \n",
    "    detected_patterns = []\n",
    "    risk_score = 0\n",
    "    \n",
    "    content_lower = content.lower()\n",
    "    for indicator in fraud_indicators:\n",
    "        if indicator in content_lower:\n",
    "            detected_patterns.append(indicator)\n",
    "            risk_score += 10\n",
    "    \n",
    "    # Use LLM for advanced analysis\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Analyze this {content_type} content for investment fraud indicators:\n",
    "    \n",
    "    Content: {content}\n",
    "    \n",
    "    Look for:\n",
    "    1. Unrealistic return promises\n",
    "    2. Pressure tactics and urgency\n",
    "    3. Lack of proper disclaimers\n",
    "    4. Unverified credentials\n",
    "    5. Social media manipulation tactics\n",
    "    \n",
    "    Provide a detailed fraud risk assessment.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = await llm_with_search.acomplete(analysis_prompt)\n",
    "    \n",
    "    # Store in database\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"fraud_scans\" not in current_state:\n",
    "        current_state[\"fraud_scans\"] = []\n",
    "    \n",
    "    scan_result = {\n",
    "        \"content\": content[:200] + \"...\" if len(content) > 200 else content,\n",
    "        \"type\": content_type,\n",
    "        \"detected_patterns\": detected_patterns,\n",
    "        \"risk_score\": min(risk_score, 100),\n",
    "        \"ai_analysis\": str(response),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    current_state[\"fraud_scans\"].append(scan_result)\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return f\"Content scanned. Risk Score: {scan_result['risk_score']}/100. Patterns detected: {detected_patterns}\"\n",
    "\n",
    "async def verify_advisor_credentials(ctx: Context, advisor_name: str, registration_number: str = None) -> str:\n",
    "    \"\"\"Verifies advisor credentials against SEBI regulatory database\"\"\"\n",
    "    \n",
    "    # Search SEBI database (simulated - in production, integrate with actual SEBI APIs)\n",
    "    verification_prompt = f\"\"\"\n",
    "    Verify the credentials of investment advisor: {advisor_name}\n",
    "    Registration Number: {registration_number if registration_number else \"Not provided\"}\n",
    "    \n",
    "    Search for:\n",
    "    1. SEBI registration status\n",
    "    2. Valid license and category\n",
    "    3. Any disciplinary actions\n",
    "    4. Contact information verification\n",
    "    5. Recent regulatory updates\n",
    "    \n",
    "    Provide verification status and any red flags.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = await llm_with_search.acomplete(verification_prompt)\n",
    "    \n",
    "    # Store verification result\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"advisor_verifications\" not in current_state:\n",
    "        current_state[\"advisor_verifications\"] = []\n",
    "    \n",
    "    verification_result = {\n",
    "        \"advisor_name\": advisor_name,\n",
    "        \"registration_number\": registration_number,\n",
    "        \"verification_result\": str(response),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    current_state[\"advisor_verifications\"].append(verification_result)\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return f\"Advisor verification completed for {advisor_name}. Check results in verification database.\"\n",
    "\n",
    "async def monitor_social_media(ctx: Context, platform: str, search_terms: str) -> str:\n",
    "    \"\"\"Monitors social media platforms for suspicious investment content\"\"\"\n",
    "    \n",
    "    monitoring_prompt = f\"\"\"\n",
    "    Monitor {platform} for suspicious investment content related to: {search_terms}\n",
    "    \n",
    "    Look for:\n",
    "    1. Pump and dump schemes\n",
    "    2. Fake trading apps promotion\n",
    "    3. Impersonation of legitimate advisors\n",
    "    4. Coordinated market manipulation\n",
    "    5. Misleading stock tips\n",
    "    6. IPO allotment frauds\n",
    "    \n",
    "    Identify patterns, user behaviors, and potential fraud networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = await llm_with_search.acomplete(monitoring_prompt)\n",
    "    \n",
    "    # Store monitoring results\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"social_media_monitoring\" not in current_state:\n",
    "        current_state[\"social_media_monitoring\"] = []\n",
    "    \n",
    "    monitoring_result = {\n",
    "        \"platform\": platform,\n",
    "        \"search_terms\": search_terms,\n",
    "        \"findings\": str(response),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    current_state[\"social_media_monitoring\"].append(monitoring_result)\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return f\"Social media monitoring completed for {platform}. Suspicious activities logged.\"\n",
    "\n",
    "async def analyze_corporate_announcement(ctx: Context, announcement_text: str, company_name: str) -> str:\n",
    "    \"\"\"Analyzes corporate announcements for authenticity and credibility\"\"\"\n",
    "    \n",
    "    analysis_prompt = f\"\"\"\n",
    "    Analyze this corporate announcement for authenticity and credibility:\n",
    "    \n",
    "    Company: {company_name}\n",
    "    Announcement: {announcement_text}\n",
    "    \n",
    "    Verify:\n",
    "    1. Official company communication channels\n",
    "    2. Consistency with historical performance\n",
    "    3. Regulatory filing requirements\n",
    "    4. Cross-verification with exchange announcements\n",
    "    5. Credibility of claimed partnerships/deals\n",
    "    6. Market impact plausibility\n",
    "    \n",
    "    Provide credibility score (1-10) and authenticity assessment.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = await llm_with_search.acomplete(analysis_prompt)\n",
    "    \n",
    "    # Store analysis\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"announcement_analysis\" not in current_state:\n",
    "        current_state[\"announcement_analysis\"] = []\n",
    "    \n",
    "    analysis_result = {\n",
    "        \"company_name\": company_name,\n",
    "        \"announcement\": announcement_text[:300] + \"...\" if len(announcement_text) > 300 else announcement_text,\n",
    "        \"analysis\": str(response),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    current_state[\"announcement_analysis\"].append(analysis_result)\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return f\"Corporate announcement analyzed for {company_name}. Credibility assessment completed.\"\n",
    "\n",
    "async def generate_fraud_report(ctx: Context, report_type: str = \"comprehensive\") -> str:\n",
    "    \"\"\"Generates comprehensive fraud detection report with risk assessments\"\"\"\n",
    "    \n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    # Compile all findings\n",
    "    report_data = {\n",
    "        \"fraud_scans\": current_state.get(\"fraud_scans\", []),\n",
    "        \"advisor_verifications\": current_state.get(\"advisor_verifications\", []),\n",
    "        \"social_media_monitoring\": current_state.get(\"social_media_monitoring\", []),\n",
    "        \"announcement_analysis\": current_state.get(\"announcement_analysis\", [])\n",
    "    }\n",
    "    \n",
    "    report_prompt = f\"\"\"\n",
    "    Generate a comprehensive fraud detection report based on these findings:\n",
    "    \n",
    "    {json.dumps(report_data, indent=2)}\n",
    "    \n",
    "    Include:\n",
    "    1. Executive Summary of fraud risks identified\n",
    "    2. High-risk content and advisors flagged\n",
    "    3. Social media threats and manipulation attempts\n",
    "    4. Corporate announcement authenticity issues\n",
    "    5. Actionable recommendations for investors\n",
    "    6. Regulatory alerts and compliance issues\n",
    "    7. Risk mitigation strategies\n",
    "    \n",
    "    Format as a professional security report for SEBI and retail investors.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = await llm_with_search.acomplete(report_prompt)\n",
    "    \n",
    "    current_state[\"fraud_report\"] = {\n",
    "        \"report_content\": str(response),\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"report_type\": report_type\n",
    "    }\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    \n",
    "    return f\"Comprehensive fraud detection report generated. Report contains analysis of all detected threats.\"\n",
    "\n",
    "print(\"✅ Fraud Detection Tools Initialized Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc993b19",
   "metadata": {},
   "source": [
    "## Build Multi-Agent Fraud Detection System\n",
    "\n",
    "The fraud detection system consists of specialized agents working collaboratively:\n",
    "\n",
    "### 🔍 **Content Scanner Agent**\n",
    "- **Primary Role**: Identifies and analyzes suspicious investment content\n",
    "- **Capabilities**: Text analysis, pattern recognition, fraud indicator detection\n",
    "- **Handoff**: Can escalate to Advisor Verification Agent for credential checks\n",
    "\n",
    "### ✅ **Advisor Verification Agent** \n",
    "- **Primary Role**: Validates investment advisor credentials and legitimacy\n",
    "- **Capabilities**: SEBI database queries, license verification, background checks\n",
    "- **Handoff**: Works with Social Media Monitor for impersonation detection\n",
    "\n",
    "### 📱 **Social Media Monitor Agent**\n",
    "- **Primary Role**: Scans social platforms for fraudulent investment schemes\n",
    "- **Capabilities**: Platform monitoring, viral content analysis, network mapping\n",
    "- **Handoff**: Coordinates with Corporate Announcement Analyzer for cross-verification\n",
    "\n",
    "### 📊 **Corporate Announcement Analyzer**\n",
    "- **Primary Role**: Verifies authenticity of company announcements and press releases\n",
    "- **Capabilities**: Document verification, historical analysis, credibility scoring\n",
    "- **Handoff**: Provides data to Risk Assessment Agent for final evaluation\n",
    "\n",
    "### ⚠️ **Risk Assessment Agent**\n",
    "- **Primary Role**: Generates comprehensive fraud reports and risk scores\n",
    "- **Capabilities**: Data aggregation, threat analysis, recommendation generation\n",
    "- **Output**: Final fraud detection reports for regulators and investors\n",
    "\n",
    "Each agent maintains specialized knowledge and can collaborate seamlessly to provide comprehensive protection against investment fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d94cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All Fraud Detection Agents Created Successfully!\n",
      "\n",
      "🤖 Available Agents:\n",
      "- ContentScannerAgent: Content fraud detection\n",
      "- AdvisorVerificationAgent: Credential verification\n",
      "- SocialMediaMonitorAgent: Platform monitoring\n",
      "- CorporateAnnouncementAnalyzer: Announcement verification\n",
      "- RiskAssessmentAgent: Risk scoring & reporting\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "from llama_index.core.agent.workflow import FunctionAgent, ReActAgent\n",
    "\n",
    "# 🔍 Content Scanner Agent\n",
    "content_scanner_agent = FunctionAgent(\n",
    "    name=\"ContentScannerAgent\",\n",
    "    description=\"Scans and analyzes content for investment fraud indicators, suspicious patterns, and deceptive tactics.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ContentScannerAgent specialized in detecting investment fraud. \"\n",
    "        \"Analyze all content for fraud indicators like unrealistic returns, pressure tactics, fake credentials, and deceptive language. \"\n",
    "        \"When suspicious advisors are mentioned, hand off to AdvisorVerificationAgent for credential verification. \"\n",
    "        \"Focus on protecting retail investors from fraudulent schemes and misleading content.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[scan_content_for_fraud],\n",
    "    can_handoff_to=[\"AdvisorVerificationAgent\", \"SocialMediaMonitorAgent\"],\n",
    ")\n",
    "\n",
    "# ✅ Advisor Verification Agent\n",
    "advisor_verification_agent = FunctionAgent(\n",
    "    name=\"AdvisorVerificationAgent\", \n",
    "    description=\"Verifies investment advisor credentials against SEBI regulatory database and flags impersonators.\",\n",
    "    system_prompt=(\n",
    "        \"You are the AdvisorVerificationAgent responsible for validating investment advisor credentials. \"\n",
    "        \"Cross-reference all advisor claims with SEBI registration database. \"\n",
    "        \"Flag unregistered entities, expired licenses, and impersonators. \"\n",
    "        \"Work with SocialMediaMonitorAgent to track advisor impersonation across platforms. \"\n",
    "        \"Ensure only legitimate advisors are trusted by retail investors.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[verify_advisor_credentials],\n",
    "    can_handoff_to=[\"SocialMediaMonitorAgent\", \"RiskAssessmentAgent\"],\n",
    ")\n",
    "\n",
    "# 📱 Social Media Monitor Agent  \n",
    "social_media_monitor_agent = FunctionAgent(\n",
    "    name=\"SocialMediaMonitorAgent\",\n",
    "    description=\"Monitors social media platforms for fraudulent investment schemes, pump-and-dump activities, and manipulative content.\",\n",
    "    system_prompt=(\n",
    "        \"You are the SocialMediaMonitorAgent that monitors social platforms for investment fraud. \"\n",
    "        \"Detect pump-and-dump schemes, fake trading apps, WhatsApp/Telegram fraud groups, and viral misinformation. \"\n",
    "        \"Track coordinated manipulation attempts and identify fraud networks. \"\n",
    "        \"Hand off corporate announcement verification to CorporateAnnouncementAnalyzer when company-related fraud is detected. \"\n",
    "        \"Protect investors from social media-based financial fraud.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[monitor_social_media],\n",
    "    can_handoff_to=[\"CorporateAnnouncementAnalyzer\", \"RiskAssessmentAgent\"],\n",
    ")\n",
    "\n",
    "# 📊 Corporate Announcement Analyzer\n",
    "corporate_announcement_analyzer = FunctionAgent(\n",
    "    name=\"CorporateAnnouncementAnalyzer\",\n",
    "    description=\"Analyzes corporate announcements for authenticity, verifies claims, and provides credibility scoring.\",\n",
    "    system_prompt=(\n",
    "        \"You are the CorporateAnnouncementAnalyzer that verifies corporate announcements and press releases. \"\n",
    "        \"Cross-check announcements with historical filings, counterparty disclosures, and regulatory databases. \"\n",
    "        \"Identify fabricated news, misleading claims, and market manipulation attempts. \"\n",
    "        \"Provide credibility scores and flag suspicious announcements that could mislead investors. \"\n",
    "        \"Hand off to RiskAssessmentAgent for final fraud risk evaluation.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[analyze_corporate_announcement],\n",
    "    can_handoff_to=[\"RiskAssessmentAgent\"],\n",
    ")\n",
    "\n",
    "# ⚠️ Risk Assessment Agent\n",
    "risk_assessment_agent = FunctionAgent(\n",
    "    name=\"RiskAssessmentAgent\",\n",
    "    description=\"Generates comprehensive fraud reports, risk scores, and actionable recommendations for investors and regulators.\",\n",
    "    system_prompt=(\n",
    "        \"You are the RiskAssessmentAgent that provides final fraud risk assessment and generates comprehensive reports. \"\n",
    "        \"Aggregate findings from all agents to create detailed fraud analysis reports. \"\n",
    "        \"Provide risk scores, investor warnings, and regulatory recommendations. \"\n",
    "        \"Generate actionable insights for SEBI, exchanges, and retail investors to prevent financial fraud. \"\n",
    "        \"Your reports should be clear, comprehensive, and focused on investor protection.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[generate_fraud_report],\n",
    "    can_handoff_to=[\"ContentScannerAgent\"],  # Can restart investigation cycle\n",
    ")\n",
    "\n",
    "print(\"✅ All Fraud Detection Agents Created Successfully!\")\n",
    "print(\"\\n🤖 Available Agents:\")\n",
    "print(\"- ContentScannerAgent: Content fraud detection\")\n",
    "print(\"- AdvisorVerificationAgent: Credential verification\")  \n",
    "print(\"- SocialMediaMonitorAgent: Platform monitoring\")\n",
    "print(\"- CorporateAnnouncementAnalyzer: Announcement verification\")\n",
    "print(\"- RiskAssessmentAgent: Risk scoring & reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a31e58",
   "metadata": {},
   "source": [
    "## Initialize Fraud Detection Workflow\n",
    "\n",
    "Now we'll create the **AgentWorkflow** that orchestrates all fraud detection agents. The workflow starts with the **ContentScannerAgent** as the root agent, which analyzes incoming content and hands off to specialized agents as needed.\n",
    "\n",
    "The workflow maintains state across all fraud detection activities and ensures comprehensive analysis of potential threats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6267128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 SEBI Fraud Detection System Ready!\n",
      "==================================================\n",
      "📊 System Status: Operational\n",
      "🔍 Active Agents: 5\n",
      "🛡️ Root Agent: ContentScannerAgent\n",
      "📱 Monitoring: Social Media, Websites, Announcements\n",
      "✅ Database: Regulatory verification enabled\n",
      "🤖 AI Engine: Gemini 2.5 Pro\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "# Create Fraud Detection Workflow\n",
    "fraud_detection_workflow = AgentWorkflow(\n",
    "    agents=[\n",
    "        content_scanner_agent,\n",
    "        advisor_verification_agent, \n",
    "        social_media_monitor_agent,\n",
    "        corporate_announcement_analyzer,\n",
    "        risk_assessment_agent\n",
    "    ],\n",
    "    root_agent=content_scanner_agent.name,\n",
    "    initial_state={\n",
    "        \"fraud_scans\": [],\n",
    "        \"advisor_verifications\": [],\n",
    "        \"social_media_monitoring\": [],\n",
    "        \"announcement_analysis\": [],\n",
    "        \"fraud_report\": {\n",
    "            \"status\": \"Initialized\",\n",
    "            \"total_threats_detected\": 0,\n",
    "            \"high_risk_items\": [],\n",
    "            \"recommendations\": []\n",
    "        },\n",
    "        \"session_metadata\": {\n",
    "            \"started_at\": datetime.now().isoformat(),\n",
    "            \"session_id\": f\"fraud_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            \"platform\": \"SEBI Fraud Detection System\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"🚨 SEBI Fraud Detection System Ready!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"📊 System Status: Operational\")\n",
    "print(f\"🔍 Active Agents: {len(fraud_detection_workflow.agents)}\")\n",
    "print(f\"🛡️ Root Agent: {fraud_detection_workflow.root_agent}\")\n",
    "print(\"📱 Monitoring: Social Media, Websites, Announcements\")\n",
    "print(\"✅ Database: Regulatory verification enabled\") \n",
    "print(\"🤖 AI Engine: Gemini 2.5 Pro\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac660a7d",
   "metadata": {},
   "source": [
    "## Execute Fraud Detection Analysis\n",
    "\n",
    "The system will now analyze a real-world fraud scenario involving multiple threat vectors:\n",
    "- Suspicious investment offers with unrealistic returns\n",
    "- Unverified advisor credentials  \n",
    "- Social media manipulation tactics\n",
    "- Potentially fake corporate announcements\n",
    "\n",
    "Watch as different agents collaborate to provide comprehensive fraud detection and risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c9d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 INITIATING COMPREHENSIVE FRAUD DETECTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "🔥 =============== ContentScannerAgent ===============\n",
      "🛠️  Using Tools: scan_content_for_fraud, scan_content_for_fraud, scan_content_for_fraud, scan_content_for_fraud\n",
      "🔨 Executing: scan_content_for_fraud\n",
      "🔨 Executing: scan_content_for_fraud\n",
      "🔨 Executing: scan_content_for_fraud\n",
      "🔨 Executing: scan_content_for_fraud\n",
      "🔧 Tool: scan_content_for_fraud\n",
      "   Input: {'content': '🚀 URGENT: Buy XYZ Corp before announcement tomorrow!\\nInsider information confirms 500%...\n",
      "   Result: Content scanned. Risk Score: 0/100. Patterns detected: []...\n",
      "🔧 Tool: scan_content_for_fraud\n",
      "   Input: {'content_type': 'text', 'content': '🔥 GUARANTEED 800% RETURNS in 45 days! 🔥\\nJoin our EXCLUSIVE tra...\n",
      "   Result: Content scanned. Risk Score: 30/100. Patterns detected: ['secret algorithm', 'risk-free', 'act now']...\n",
      "🔧 Tool: scan_content_for_fraud\n",
      "   Input: {'content': \"📱 Download TradeGuru Pro - India's #1 trading platform!\\n⭐ 5-star ratings ⭐ Used by 10 ...\n",
      "   Result: Content scanned. Risk Score: 0/100. Patterns detected: []...\n",
      "🔧 Tool: scan_content_for_fraud\n",
      "   Input: {'content': 'ABC Industries announces revolutionary AI partnership with Google and Microsoft.\\nExpec...\n",
      "   Result: Content scanned. Risk Score: 0/100. Patterns detected: []...\n",
      "🛠️  Using Tools: handoff\n",
      "🔨 Executing: handoff\n",
      "🔧 Tool: handoff\n",
      "   Input: {'to_agent': 'AdvisorVerificationAgent', 'reason': 'Verification of investment advisor Rajesh Sharma...\n",
      "   Result: Agent AdvisorVerificationAgent is now handling the request due to the following reason: Verification of investment advisor Rajesh Sharma with suspicio...\n",
      "\n",
      "✅ =============== AdvisorVerificationAgent ===============\n",
      "📤 Analysis: Here is a comprehensive fraud analysis of the multi-layered scenario:\n",
      "\n",
      "**1. SUSPICIOUS INVESTMENT OFFER:**\n",
      "This offer exhibits several classic fraud indicators:\n",
      "*   **Unrealistic Returns:** \"GUARANTEE...\n",
      "\n",
      "🚨 FRAUD DETECTION COMPLETED - 5 THREATS ANALYZED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "\n",
    "# Comprehensive Fraud Detection Scenario\n",
    "fraud_scenario = \"\"\"\n",
    "🚨 URGENT FRAUD DETECTION REQUEST 🚨\n",
    "\n",
    "Analyze the following multi-layered fraud scenario:\n",
    "\n",
    "1. SUSPICIOUS INVESTMENT OFFER:\n",
    "\"🔥 GUARANTEED 800% RETURNS in 45 days! 🔥\n",
    "Join our EXCLUSIVE trading group with SECRET ALGORITHMS used by billionaires!\n",
    "✅ Risk-FREE investment ✅ No experience needed\n",
    "📞 Contact certified advisor: Rajesh Sharma (SEBI Reg: IA/2024/FAKE999)\n",
    "💎 Limited slots available - ACT NOW or MISS OUT FOREVER!\"\n",
    "\n",
    "2. SOCIAL MEDIA MANIPULATION:\n",
    "WhatsApp group \"💰 Mumbai Stock Tips 💰\" with 5000+ members sharing:\n",
    "\"🚀 URGENT: Buy XYZ Corp before announcement tomorrow! \n",
    "Insider information confirms 500% jump! \n",
    "Trust me, I made ₹50 lakhs last week! \n",
    "Delete after reading!\"\n",
    "\n",
    "3. SUSPICIOUS CORPORATE ANNOUNCEMENT:\n",
    "\"ABC Industries announces revolutionary AI partnership with Google and Microsoft.\n",
    "Expected revenue impact: ₹10,000 crores in next quarter.\n",
    "Stock price target revised to ₹5000 (current: ₹100)\n",
    "Press release signed by CEO John Smith\"\n",
    "\n",
    "4. FAKE TRADING APP:\n",
    "\"📱 Download TradeGuru Pro - India's #1 trading platform!\n",
    "⭐ 5-star ratings ⭐ Used by 10 lakh+ investors\n",
    "🎁 Sign up bonus: ₹10,000 free trading credits\n",
    "✨ Developed by IIT graduates, approved by RBI\"\n",
    "\n",
    "TASK: Conduct comprehensive fraud analysis covering all aspects.\n",
    "\"\"\"\n",
    "\n",
    "print(\"🚨 INITIATING COMPREHENSIVE FRAUD DETECTION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Execute the fraud detection workflow\n",
    "handler = fraud_detection_workflow.run(user_msg=fraud_scenario)\n",
    "\n",
    "current_agent = None\n",
    "threat_count = 0\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if (\n",
    "        hasattr(event, \"current_agent_name\")\n",
    "        and event.current_agent_name != current_agent\n",
    "    ):\n",
    "        current_agent = event.current_agent_name\n",
    "        print(f\"\\n{'🔥' if 'Scanner' in current_agent else '✅' if 'Verification' in current_agent else '📱' if 'Monitor' in current_agent else '📊' if 'Analyzer' in current_agent else '⚠️'} {'='*15} {current_agent} {'='*15}\")\n",
    "        \n",
    "    elif isinstance(event, AgentOutput):\n",
    "        if event.response.content:\n",
    "            print(f\"📤 Analysis: {event.response.content[:200]}...\")\n",
    "        if event.tool_calls:\n",
    "            tool_names = [call.tool_name for call in event.tool_calls]\n",
    "            print(f\"🛠️  Using Tools: {', '.join(tool_names)}\")\n",
    "            \n",
    "    elif isinstance(event, ToolCallResult):\n",
    "        threat_count += 1\n",
    "        print(f\"🔧 Tool: {event.tool_name}\")\n",
    "        print(f\"   Input: {str(event.tool_kwargs)[:100]}...\")\n",
    "        print(f\"   Result: {str(event.tool_output)[:150]}...\")\n",
    "        \n",
    "    elif isinstance(event, ToolCall):\n",
    "        print(f\"🔨 Executing: {event.tool_name}\")\n",
    "\n",
    "print(f\"\\n🚨 FRAUD DETECTION COMPLETED - {threat_count} THREATS ANALYZED\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97f7c1",
   "metadata": {},
   "source": [
    "## Final Fraud Detection Report\n",
    "\n",
    "Generate the comprehensive fraud detection report with all findings, risk assessments, and actionable recommendations for SEBI, exchanges, and retail investors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b2fa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨================================================================================🚨\n",
      "             SEBI FRAUD DETECTION SYSTEM - COMPREHENSIVE REPORT\n",
      "🚨================================================================================🚨\n",
      "\n",
      "🔍 CONTENT SCANS PERFORMED: 4\n",
      "\n",
      "   Scan #1:\n",
      "   ⚠️  Risk Score: 0/100\n",
      "   🔍 Patterns: \n",
      "   📝 Content: 🚀 URGENT: Buy XYZ Corp before announcement tomorrow!\n",
      "Insider information confirms 500% jump!\n",
      "Trust me, I made ₹50 lakhs last week!\n",
      "Delete after reading!\n",
      "\n",
      "   Scan #2:\n",
      "   ⚠️  Risk Score: 30/100\n",
      "   🔍 Patterns: secret algorithm, risk-free, act now\n",
      "   📝 Content: 🔥 GUARANTEED 800% RETURNS in 45 days! 🔥\n",
      "Join our EXCLUSIVE trading group with SECRET ALGORITHMS used by billionaires!\n",
      "✅ Risk-FREE investment ✅ No experience needed\n",
      "📞 Contact certified advisor: Rajesh ...\n",
      "\n",
      "   Scan #3:\n",
      "   ⚠️  Risk Score: 0/100\n",
      "   🔍 Patterns: \n",
      "   📝 Content: 📱 Download TradeGuru Pro - India's #1 trading platform!\n",
      "⭐ 5-star ratings ⭐ Used by 10 lakh+ investors\n",
      "🎁 Sign up bonus: ₹10,000 free trading credits\n",
      "✨ Developed by IIT graduates, approved by RBI\n",
      "\n",
      "   Scan #4:\n",
      "   ⚠️  Risk Score: 0/100\n",
      "   🔍 Patterns: \n",
      "   📝 Content: ABC Industries announces revolutionary AI partnership with Google and Microsoft.\n",
      "Expected revenue impact: ₹10,000 crores in next quarter.\n",
      "Stock price target revised to ₹5000 (current: ₹100)\n",
      "Press rele...\n",
      "\n",
      "✅ ADVISOR VERIFICATIONS: 0\n",
      "\n",
      "📱 SOCIAL MEDIA MONITORING: 0\n",
      "\n",
      "📊 CORPORATE ANNOUNCEMENTS ANALYZED: 0\n",
      "\n",
      "📈 SESSION SUMMARY:\n",
      "------------------------------\n",
      "🔗 Session ID: fraud_detection_20250905_232901\n",
      "⏰ Started: 2025-09-05T23:29:01.790971\n",
      "🛡️  Platform: SEBI Fraud Detection System\n",
      "🤖 AI Engine: Gemini 2.5 Pro\n",
      "\n",
      "🎯 KEY RECOMMENDATIONS:\n",
      "------------------------------\n",
      "1. 🚫 Block suspicious investment offers with unrealistic return promises\n",
      "2. ⚠️  Alert investors about unverified advisor credentials\n",
      "3. 📱 Monitor and shut down fraudulent social media groups\n",
      "4. 📊 Verify corporate announcements through official channels\n",
      "5. 🔍 Implement real-time scanning of all investment platforms\n",
      "6. 📚 Educate retail investors about common fraud patterns\n",
      "\n",
      "🚨================================================================================🚨\n",
      "          END OF FRAUD DETECTION REPORT - STAY VIGILANT!\n",
      "🚨================================================================================🚨\n"
     ]
    }
   ],
   "source": [
    "# Generate and display comprehensive fraud detection report\n",
    "state = await handler.ctx.store.get(\"state\")\n",
    "\n",
    "print(\"🚨\" + \"=\"*80 + \"🚨\")\n",
    "print(\"             SEBI FRAUD DETECTION SYSTEM - COMPREHENSIVE REPORT\")  \n",
    "print(\"🚨\" + \"=\"*80 + \"🚨\")\n",
    "\n",
    "# Display fraud report if generated\n",
    "if \"fraud_report\" in state and \"report_content\" in state[\"fraud_report\"]:\n",
    "    print(\"\\n📊 EXECUTIVE SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(state[\"fraud_report\"][\"report_content\"])\n",
    "\n",
    "# Display individual analysis results\n",
    "print(f\"\\n🔍 CONTENT SCANS PERFORMED: {len(state.get('fraud_scans', []))}\")\n",
    "for i, scan in enumerate(state.get('fraud_scans', []), 1):\n",
    "    print(f\"\\n   Scan #{i}:\")\n",
    "    print(f\"   ⚠️  Risk Score: {scan['risk_score']}/100\")\n",
    "    print(f\"   🔍 Patterns: {', '.join(scan['detected_patterns'])}\")\n",
    "    print(f\"   📝 Content: {scan['content']}\")\n",
    "\n",
    "print(f\"\\n✅ ADVISOR VERIFICATIONS: {len(state.get('advisor_verifications', []))}\")\n",
    "for i, verification in enumerate(state.get('advisor_verifications', []), 1):\n",
    "    print(f\"\\n   Verification #{i}:\")\n",
    "    print(f\"   👤 Advisor: {verification['advisor_name']}\")\n",
    "    print(f\"   📋 Registration: {verification.get('registration_number', 'Not provided')}\")\n",
    "\n",
    "print(f\"\\n📱 SOCIAL MEDIA MONITORING: {len(state.get('social_media_monitoring', []))}\")\n",
    "for i, monitoring in enumerate(state.get('social_media_monitoring', []), 1):\n",
    "    print(f\"\\n   Monitoring #{i}:\")\n",
    "    print(f\"   🌐 Platform: {monitoring['platform']}\")\n",
    "    print(f\"   🔎 Search Terms: {monitoring['search_terms']}\")\n",
    "\n",
    "print(f\"\\n📊 CORPORATE ANNOUNCEMENTS ANALYZED: {len(state.get('announcement_analysis', []))}\")\n",
    "for i, analysis in enumerate(state.get('announcement_analysis', []), 1):\n",
    "    print(f\"\\n   Analysis #{i}:\")\n",
    "    print(f\"   🏢 Company: {analysis['company_name']}\")\n",
    "    print(f\"   📄 Announcement: {analysis['announcement']}\")\n",
    "\n",
    "# Session metadata\n",
    "session_data = state.get('session_metadata', {})\n",
    "print(f\"\\n📈 SESSION SUMMARY:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"🔗 Session ID: {session_data.get('session_id', 'N/A')}\")\n",
    "print(f\"⏰ Started: {session_data.get('started_at', 'N/A')}\")\n",
    "print(f\"🛡️  Platform: {session_data.get('platform', 'SEBI Fraud Detection System')}\")\n",
    "print(f\"🤖 AI Engine: Gemini 2.5 Pro\")\n",
    "\n",
    "# Final recommendations\n",
    "print(f\"\\n🎯 KEY RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"1. 🚫 Block suspicious investment offers with unrealistic return promises\")\n",
    "print(\"2. ⚠️  Alert investors about unverified advisor credentials\")  \n",
    "print(\"3. 📱 Monitor and shut down fraudulent social media groups\")\n",
    "print(\"4. 📊 Verify corporate announcements through official channels\")\n",
    "print(\"5. 🔍 Implement real-time scanning of all investment platforms\")\n",
    "print(\"6. 📚 Educate retail investors about common fraud patterns\")\n",
    "\n",
    "print(\"\\n\" + \"🚨\" + \"=\"*80 + \"🚨\")\n",
    "print(\"          END OF FRAUD DETECTION REPORT - STAY VIGILANT!\")\n",
    "print(\"🚨\" + \"=\"*80 + \"🚨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46d645",
   "metadata": {},
   "source": [
    "## 🌐 Launch Web Interface\n",
    "\n",
    "The fraud detection system includes a **Google-like web interface** for easy access by regulators, investors, and compliance teams. The interface provides:\n",
    "\n",
    "### 📱 **Key Features:**\n",
    "- **🔍 Content Scanner**: Real-time fraud detection and analysis\n",
    "- **✅ Advisor Verification**: SEBI credential validation\n",
    "- **📱 Social Media Monitor**: Platform monitoring dashboard  \n",
    "- **📊 Corporate Announcements**: Authenticity verification\n",
    "- **⚠️ Risk Assessment**: Comprehensive threat analysis\n",
    "\n",
    "### 🚀 **To Launch the Web Interface:**\n",
    "\n",
    "1. **Install requirements**: `pip install -r web_requirements.txt`\n",
    "2. **Set up environment**: Add your `GEMINI_API_KEY` to `.env` file\n",
    "3. **Run the launcher**: `python run_web_app.py`\n",
    "4. **Access interface**: Open http://localhost:8501 in your browser\n",
    "\n",
    "The web interface provides an intuitive, Google-inspired design that makes fraud detection accessible to all stakeholders while maintaining enterprise-grade security and compliance standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the SEBI Fraud Detection Web Interface\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def launch_fraud_detection_web():\n",
    "    \"\"\"Launch the fraud detection web interface\"\"\"\n",
    "    \n",
    "    print(\"🛡️  SEBI FRAUD DETECTION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🌐 Google-like Web Interface Ready!\")\n",
    "    print(\"📊 Features: Content Scanner, Advisor Verification, Social Media Monitor\")\n",
    "    print(\"🔍 AI-Powered: Gemini 2.5 Pro fraud detection\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if web files exist\n",
    "    web_app_path = Path(\"fraud_detection_web.py\")\n",
    "    launcher_path = Path(\"run_web_app.py\")\n",
    "    \n",
    "    if web_app_path.exists() and launcher_path.exists():\n",
    "        print(\"✅ Web interface files found!\")\n",
    "        print(\"🚀 To launch the web app, run:\")\n",
    "        print(\"   📝 python run_web_app.py\")\n",
    "        print(\"   🌐 Then open: http://localhost:8501\")\n",
    "        print(\"\\n🔧 Prerequisites:\")\n",
    "        print(\"   📦 pip install streamlit plotly pandas\")\n",
    "        print(\"   🔑 Set GEMINI_API_KEY in environment\")\n",
    "        \n",
    "        # Option to launch directly (commented out for safety)\n",
    "        \"\"\"\n",
    "        launch_choice = input(\"\\\\n🚀 Launch web interface now? (y/n): \")\n",
    "        if launch_choice.lower() == 'y':\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"run_web_app.py\"])\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error: {e}\")\n",
    "        \"\"\"\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Web interface files not found!\")\n",
    "        print(\"💡 Make sure fraud_detection_web.py and run_web_app.py are in the current directory\")\n",
    "    \n",
    "    print(\"\\n🎯 Web Interface Features:\")\n",
    "    print(\"- 🔍 Real-time content fraud scanning\")\n",
    "    print(\"- ✅ SEBI advisor credential verification\")\n",
    "    print(\"- 📱 Social media monitoring dashboard\")\n",
    "    print(\"- 📊 Corporate announcement analysis\")\n",
    "    print(\"- ⚠️ Comprehensive risk assessment\")\n",
    "    print(\"- 🛡️  Google-inspired design for ease of use\")\n",
    "\n",
    "# Run the launch function\n",
    "launch_fraud_detection_web()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
